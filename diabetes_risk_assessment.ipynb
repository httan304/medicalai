{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes-risk-assessment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbosstech/disease-diagnostic-from-symptoms/blob/master/diabetes_risk_assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2UeCDO2FQrFb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Workflow on Diabetes Data"
      ]
    },
    {
      "metadata": {
        "id": "D_z69PZZQrFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0p79Wh5QrFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1.  Data Preparation\n",
        "`Acquiring and the preparation of a Data-set`"
      ]
    },
    {
      "metadata": {
        "id": "-MXUSvcQQrFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the [Pima Indians Diabetes Database](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) provided by the UCI Machine Learning Repository."
      ]
    },
    {
      "metadata": {
        "id": "Tg_msDBmQrFi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2.   Data Exploration\n",
        "\n",
        "Analyse and “**get to know**” the data-set: potential features & to see if data cleaning\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "H2XOJb7L7Cvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tg_fAxWyQrFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes = pd.read_csv('/content/gdrive/My Drive/machine-learning/disease-diagnostic-from-symptoms/dataset/diabetes.csv')\n",
        "print(diabetes.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3TFQ6Q1QrFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z4fL-370QrFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Diabetes data set dimensions : {}\".format(diabetes.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sIEEAr8kQrFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes.groupby('Outcome').size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MPt0xreG0-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   **Visualize** to understand & explain the Data: using *Matplotlib*, *Seaborn*.\n",
        "*   to find the **data distribution** of the **features**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "--pblq7mQrF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes.hist(figsize=(9, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRbk_yhTQrF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# histograms for the two responses separately. \n",
        "diabetes.groupby('Outcome').hist(figsize=(9, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Xa_8iYjOQrF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3.  Data Cleaning\n",
        "“**Better data beats fancier algorithms**”, which suggests better data gives you better resulting models. There are several factors to consider in the data cleaning process, including:\n",
        "* 3.1. Duplicate or irrelevant observations.\n",
        "* 3.2. Bad labeling of data, same category occurring multiple times.\n",
        "* 3.3. Missing or null data points.\n",
        "* 3.4. Unexpected outliers."
      ]
    },
    {
      "metadata": {
        "id": "Nlval43uLJk9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1. Duplicate or irrelevant observations.\n",
        "NA: 'cause using standard data-set"
      ]
    },
    {
      "metadata": {
        "id": "MdOAhWjdLStX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2. Bad labeling of data, same category occurring multiple times.\n",
        "NA: 'cause using standard data-set"
      ]
    },
    {
      "metadata": {
        "id": "RLBIMQHNQrF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3. Missing or Null Data points"
      ]
    },
    {
      "metadata": {
        "id": "NVCiR5eqQrF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhZA6Zy7QrGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cx3LskqNQrGH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.4. Unexpected Outliers\n",
        "Unexpected Outliers either useful or potentially harmful."
      ]
    },
    {
      "metadata": {
        "id": "z6BnFIv8QrGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A living person cannot have diastolic blood pressure of zero\n",
        "print(\"Total : \", diabetes[diabetes.BloodPressure == 0].shape[0])\n",
        "print(diabetes[diabetes.BloodPressure == 0].groupby('Outcome')['Age'].count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uL48ua2HQrGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Even after fasting glucose level would not be as low as zero.\n",
        "print(\"Total : \", diabetes[diabetes.Glucose == 0].shape[0])\n",
        "print(diabetes[diabetes.Glucose == 0].groupby('Outcome')['Age'].count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPxj3QcQQrGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Skin fold thickness can’t be less than 10 mm better yet zero.\n",
        "print(\"Total : \", diabetes[diabetes.SkinThickness == 0].shape[0])\n",
        "print(diabetes[diabetes.SkinThickness == 0].groupby('Outcome')['Age'].count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPbpUhpkQrGW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should not be 0 or close to zero unless the person is really underweight which could be life threatening.\n",
        "print(\"Total : \", diabetes[diabetes.BMI == 0].shape[0])\n",
        "print(diabetes[diabetes.BMI == 0].groupby('Outcome')['Age'].count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLnv_gMsQrGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In a rare situation a person can have zero insulin\n",
        "print(\"Total : \", diabetes[diabetes.Insulin == 0].shape[0])\n",
        "print(diabetes[diabetes.Insulin == 0].groupby('Outcome')['Age'].count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVnn5GORnsZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Handle invalid data values :**\n",
        "* **Ignore/remove these cases** : This is not actually possible in most cases because that would mean losing valuable information.It might work for “BMI”, “glucose ”and “blood pressure” whenever just a few invalid data points.\n",
        "* **Put average/mean values** : This might work for some data sets, but in our case putting a mean value to the blood pressure column would send a wrong signal to the model.\n",
        "* **Avoid using features** : It is possible to not use the features with a lot of invalid values for the model. This may work for “skin thickness” but its hard to predict that."
      ]
    },
    {
      "metadata": {
        "id": "V8w8tdhZQrGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove the rows which the “BloodPressure”, “BMI” and “Glucose” are zero.\n",
        "diabetes_mod = diabetes[(diabetes.BloodPressure != 0) & (diabetes.BMI != 0) & (diabetes.Glucose != 0)]\n",
        "print(diabetes_mod.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7lAOixFQrGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4.  Model Selection\n",
        "[Feature Engineering](https://elitedatascience.com/feature-engineering-best-practices) is the process of transforming the gathered data into features that better represent the problem that we are trying to solve to the model, to improve its performance and accuracy.\n",
        "Feature Engineering enables to highlight the **important features** and facilitate to bring **domain expertise** on the problem to the table. It also allows to **avoid overfitting the model** despite providing many input features\n",
        "\n",
        "Assign the **features to **the** X variable** and the **response to **the** y variable**."
      ]
    },
    {
      "metadata": {
        "id": "NH1zifrIQrGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Features/Response\n",
        "feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "X = diabetes_mod[feature_names]\n",
        "y = diabetes_mod.Outcome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uih6E4YXQrGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5.  Model Selection\n",
        "**Model selection** or **algorithm selection** select the model which performs best for the data-set at hand.\n",
        "\n",
        "*  Calculating the “**Classification Accuracy (Testing Accuracy)**” of a given set of classification models with their default parameters to determine which model performs better with the diabetes data-set.\n",
        "*   **Logistic Regression**, **Random Forest** & **Gradient Boost** & **Decision Tree**, **K-Nearest Neighbors**, **Support Vector Classifier**, **Gaussian Naive Bayes** to be contenders for the best classifier.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jvyb4nRGQrGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble     import RandomForestClassifier\n",
        "from sklearn.ensemble     import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes  import GaussianNB\n",
        "from sklearn.tree         import DecisionTreeClassifier\n",
        "from sklearn.neighbors    import KNeighborsClassifier\n",
        "from sklearn.svm          import SVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNANe-fjQrGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial model selection process\n",
        "models = []\n",
        "\n",
        "models.append(('LR',  LogisticRegression(solver='lbfgs', max_iter=4000)))\n",
        "models.append(('RF',  RandomForestClassifier(n_estimators=100)))\n",
        "models.append(('GB',  GradientBoostingClassifier()))\n",
        "models.append(('GNB', GaussianNB()))\n",
        "models.append(('DT',  DecisionTreeClassifier()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('SVC', SVC(gamma=0.001)))\n",
        "# models.append(('SVC', SVC(gamma='scale')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW2vWcdxQkg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluation Methods**\n",
        "General practice to avoid training and testing on the same data. The reasons are that, the goal of the model is to predict **out-of-sample data**, and the model could be overly complex leading to **overfitting**. To avoid the aforementioned problems, there are two precautions:\n",
        "* **5.1. Train/Test Split**: \n",
        "  * “**train_test_split**” method split the data set into two portions: the **training set** is used to train the model. And the **testing set** is used to test the model, and evaluate the accuracy.\n",
        "  * “**accuracy_score**” to evaluate the accuracy of the respective model in the train/test split method.\n",
        "*   **5.2. K-Fold Cross Validation** method splits the data set into **K equal partitions** (“folds”), then use 1 fold as the testing set and the union of the other folds as the **training set**. Then the model is tested for accuracy. The **average testing accuracy** of the process is the testing accuracy. Note: more accurate and use the data efficiently. "
      ]
    },
    {
      "metadata": {
        "id": "G858ddpSQrGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.1. Using Train/Test split"
      ]
    },
    {
      "metadata": {
        "id": "jXfNUAKWQrGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = diabetes_mod.Outcome, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_pubPDXQrGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "names = []\n",
        "scores = []\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    scores.append(accuracy_score(y_test, y_pred))\n",
        "    names.append(name)\n",
        "\n",
        "tr_split = pd.DataFrame({'Name': names, 'Score': scores})\n",
        "print(tr_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycNPGBhPQrG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.2. Using K-Fold cross validation"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "BlssPOjJQrG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "strat_k_fold = StratifiedKFold(n_splits=10, random_state=10)\n",
        "\n",
        "names = []\n",
        "scores = []\n",
        "\n",
        "for name, model in models:\n",
        "    \n",
        "    score = cross_val_score(model, X, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "    names.append(name)\n",
        "    scores.append(score)\n",
        "\n",
        "kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})\n",
        "print(kf_cross_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eS7jJSqxQrG4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the accuracy scores using \"seaborn\"\n",
        "axis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)\n",
        "axis.set(xlabel='Classifier Algorithm', ylabel='Accuracy')\n",
        "\n",
        "for p in axis.patches:\n",
        "    height = p.get_height()\n",
        "    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpAVbtZC3uqL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see the **Logistic Regression**, **Random Forest** and **Gradient Boosting**, **Gaussian Naive Bayes**,  have performed better than the rest. From the base level we can observe that the ***Logistic Regression*** performs better than the other algorithms."
      ]
    },
    {
      "metadata": {
        "id": "tmz943gkQrG-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 6. Feature Selection (Revisited)\n",
        "Analyze the selected model \"Logistic Regression\", and how feature importance affects it. \n",
        "* **Recursive Feature Elimination**: **RFE** works by recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
        "* **Univariate Feature Selection**: Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
        "* **Principal Component Analysis**: **PCA** uses linear algebra to transform the dataset into a compressed form. Generally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\n",
        "* **Feature Importance**: Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features."
      ]
    },
    {
      "metadata": {
        "id": "IRcpmoZLQrG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## using \"Recursive Feature Elimination\" RFE as the feature selection method.\n",
        "from sklearn.feature_selection import RFECV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ub3kF6PKQrHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "fp0Tp3YdQrHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg_model = LogisticRegression(solver='lbfgs', max_iter=4000)\n",
        "\n",
        "rfecv = RFECV(estimator=logreg_model, step=1, cv=strat_k_fold, scoring='accuracy')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Logistic Regression CV score vs No of Features')\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4xF67U46swt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Input **5 features** to the model gives the best accuracy score.\n",
        "* **RFECV** exposes **support_ ** which is another attribute to find out the features which contribute the most to predicting.\n",
        "* We can do a comparison of the model with **original features** and the **RFECV selected features ** to see if there is an improvement in the accuracy scores."
      ]
    },
    {
      "metadata": {
        "id": "p4nd1mqHQrHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_importance = list(zip(feature_names, rfecv.support_))\n",
        "\n",
        "new_features = []\n",
        "\n",
        "for key,value in enumerate(feature_importance):\n",
        "    if(value[1]) == True:\n",
        "        new_features.append(value[0])\n",
        "        \n",
        "print(new_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FyFHbOFCQrHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate accuracy scores \n",
        "X_new = diabetes_mod[new_features]\n",
        "\n",
        "initial_score = cross_val_score(logreg_model, X, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "print(\"Initial accuracy : {} \".format(initial_score))\n",
        "\n",
        "fe_score = cross_val_score(logreg_model, X_new, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "print(\"Accuracy after Feature Selection : {} \".format(fe_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SXUEpiYQrHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Boost"
      ]
    },
    {
      "metadata": {
        "id": "e0BX9Wf8QrHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gb_model = GradientBoostingClassifier()\n",
        "\n",
        "gb_rfecv = RFECV(estimator=gb_model, step=1, cv=strat_k_fold, scoring='accuracy')\n",
        "gb_rfecv.fit(X, y)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Gradient Boost CV score vs No of Features')\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(gb_rfecv.grid_scores_) + 1), gb_rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XEJAk26WQrHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_importance = list(zip(feature_names, gb_rfecv.support_))\n",
        "\n",
        "new_features = []\n",
        "\n",
        "for key,value in enumerate(feature_importance):\n",
        "    if(value[1]) == True:\n",
        "        new_features.append(value[0])\n",
        "        \n",
        "print(new_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1Gt79kQQrHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_new_gb = diabetes_mod[new_features]\n",
        "\n",
        "initial_score = cross_val_score(gb_model, X, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "print(\"Initial accuracy : {} \".format(initial_score))\n",
        "\n",
        "fe_score = cross_val_score(gb_model, X_new_gb, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "print(\"Accuracy after Feature Selection : {} \".format(fe_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2wz7iYCQrHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 7.  Model Parameter Tuning\n",
        "* Using **[Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)** for the **Model Parameter Tuning** 'cause more accurate than **Gradient Boosting**.\n",
        "* Instead of having to manually search for optimum parameters, we can easily perform an exhaustive search using the **GridSearchCV**, which does an “exhaustive search over specified parameter values for an estimator”."
      ]
    },
    {
      "metadata": {
        "id": "F25Y42jwQrHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XUCIeb_GQrHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specify parameters\n",
        "c_values = list(np.arange(1, 10))\n",
        "\n",
        "param_grid = [\n",
        "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},\n",
        "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDpQ10dvQrHi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## fit the data to the GridSearchCV, which performs a K-fold cross validation on the data for the given combinations of the parameters.\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=strat_k_fold, scoring='accuracy', iid=False)\n",
        "grid.fit(X_new, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3z51520VQrHm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## After training & scoring, GridSearchCV provides some useful attributes to find the best parameters and the best estimator.\n",
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RvNpLFhoQrHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## feed the best parameters to the Logistic Regression model and observe whether it’s accuracy has increased.\n",
        "logreg_new = LogisticRegression(C=1, multi_class='ovr', penalty='l2', solver='liblinear')\n",
        "initial_score = cross_val_score(logreg_new, X_new, y, cv=strat_k_fold, scoring='accuracy').mean()\n",
        "print(\"Final accuracy : {} \".format(initial_score))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}